DevOps: in simple term it is a process of delivering Applications & software in fast & reliable manner.
	As a DevOps Engineer, we are responsible for building, testing & deployment also some stages after deployment like monitoring & logging to make sure the application is running fine.

	In recent days, Our companies are concentrating on 3 primary factors
		Stability
		Scalability &
		Adaptability
all these can be achieved by using DevOps.

As per a report of Cloud Expo, (Europe) — 67% of the SMEs & 47% enterprises have adopted DevOps in their product engineering services. 31% of the SMEs have adopted DevOps across the entire organization.

	DevOps is a combination of process that automates process between software development and operations teams, in order to build, test and deploy application faster. The benefits of using DevOps accomodate faster software releases, optimized processes, enhanced trust, and a bility to resolve critical issues quickly.

Benefits of DevOps:
>>> Technical Benefits:
	Continuous Software delivery
	less complexity to manage
	Quicker resolution to problems

>>> Cultural Benefits:
	More productive teams
	higher rate of employee engagement

>>> Business Benefits:
	Faster delivery of features
	More steady operating environments
	Advanced communication and collaboration
	Innovation

Companies using DevOps, deploy more frequently, have shorter lead time, lesser failure rate, and faster recovery rates. DevOps guarantee problems are fixed at every stage, instead of struggling at the end of a project.As teams spend less time dealing with fixing bugs and dealing with unplanned works, DevOps teams can spend more time on innovation and value addition. 

7 stages of DevOps
1. Plan: 
	This phase includes:

    Production metrics, objects and feedback
    Requirements
    Business metrics
    Update release metrics
    Release plan, timing and business case
    Security policy and requirement

A number of IT personnel will be involved in these practices: developers, architects, security officers, continual release management etc.
Tools: JIRA
Other tools used: Rally, Trac, Redmine, XMind, Adobe XD, Zeplin, draw.io, Slack

2. Create:
	The second phase of DevOps is create. This is comprised of building, coding, and configuring the development process. 
	Activities which comes under this stage are;

    Design of the software and configuration
    Coding including code quality and performance
    Software build and build performance
    Release candidate

Tools used: Gradle, Apache Maven, Grunt, WebPack, Github, Bitbucket, Docker, BuildMaster, Slack

3. Test:
	The quality aspect of the software depends on the efficiency of testing. Early stage testing, initial validation and frequent testing ensure quality built-in to the application can be verified and issues to be tackled early. Testing is directly associated with ensuring the quality of the software release; activities designed to ensure code quality is maintained and the highest quality is deployed to the production.
	The main activities in this are:

    Acceptance testing
    Regression testing
    Security and vulnerability analysis
    Performance
    Configuration testing

Tools used: JIRA issue tracking, Bugzilla, Selenium, Mocha, Jasmine, JUnit, NUnit, JMeter, pytest, BlazeMeter, Load Impact

4. Packaging:
	Packaging phase starts once the release is ready for deployment. This stage is often referred to as Preproduction/preprod.
	Packaging consists of following activities;

    Approval/preapprovals
    Package configuration
    Triggered releases
    Release staging and holding

Tools used: Dockers, consul.io, Ansible, SaltStack, Puppet, Chef

5. Release:
	Release includes schedule, orchestration, provisioning and deploying software into production and targeted environment. Part of this process is application release automation tools that help up the packaging and deploying the application from development to production, using automation. The specific Release activities include:

    Release coordination
    Deploying and promoting applications
    Fallbacks and recovery
    Scheduled/timed releases

Tools: Jenkins, Kubernetes CI/CD

	Jenkins is an open source automation server that offers a plugin architecture to support continuous integration and delivery. It integrates with a variety of software tools in the CI/CD toolchain and distributes work across multiple platforms. In DevOps, Jenkins is been used for packaging, release, and configuration.

	Kubernetes is an open-source platform for automating deployments, scaling, and operations of application containers across clusters of hosts, providing container-centric infrastructure.

Other tools used: Dockers, Docker Hub, Docker Swarm, Travis CI, consul.io, Ansible, SaltStack, Puppet, Chef

6. Configure
	Configure comes under the operation side of DevOps. Once the software is deployed, you need additional IT infrastructure and configuration. Configuration tools aim to allow the creation of better applications with flexibility, less downtime, and enhancing an overall cost effectiveness for the business. This approach is intended to reduce as many things creating complexity as possible by removing manual configurations.
	Specific configuration activities include;

    Infrastructure storage, database and network provisioning and configuring
    Application provision and configuration

Tools used: Dockers, Jenkins, Kubernetes CI/CD, consul.io, Ansible, SaltStack, Puppet, Chef

7. Monitor
	Monitoring is an essential section in a DevOps process. It allows IT team to identify specific issues of specific releases and to know the impact on end-users. 
	Monitor related activities are:

    Performance of IT infrastructure
    End-user response and experience
    Production metrics and statistics

Tools: New Relic
	New Relic is SaaS web and mobile application performance monitoring tool that gives analytics from the customer experience perspective. It monitors availability, alerting, and notifications in real time for applications running in the cloud, on-premise, or hybrid environments.

Other tools used: Firebase Analytics, crashlytics, ELK stack — Data/BI analytics, Sumologic, Nagios, JIRA, Telegram, Slack

DevOps lifecycle phases: the 7Cs of DevOps lifecycle:
	As we mentioned earlier, everything is continuous in DevOps – from planning to monitoring. So let’s break down the entire lifecycle into seven phases where continuity is at its core.

1. Continuous development:
	It primarily focuses on project planning and coding. During this phase, project requirements are gathered and discussed with stakeholders. Once the team agrees upon the business needs, the development team starts coding for the desired requirements. It’s a continuous process where developers are required to code whenever any changes occur in the project requirement or in case of any performance issues.

Tools Used: There are no specific tools for planning, but the development team requires some tools for code maintenance. GitLab, GIT, TFS, SVN, Mercurial, Jira, BitBucket, Confluence, and Subversion are a few tools used for version control. Many companies prefer agile practices for collaboration and use Scrum, Lean, and Kanban. Among all those tools, GIT and Jira are the most popular ones used for complex projects and the outstanding collaboration between teams while developing.

2. Continuous integration
	Continuous integration is the most crucial phase in the entire DevOps lifecycle. In this phase, updated code or add-on functionalities and features are developed and integrated into existing code. Furthermore, bugs are detected and identified in the code during this phase at every step through unit testing, and then the source code is modified accordingly. This step makes integration a continuous approach where code is tested at every commit. Moreover, the tests needed are also planned in this phase.

Tools Used: Jenkins, Bamboo, GitLab CI, Buddy, TeamCity, Travis, and CircleCI are a few DevOps tools used to make the project workflow smooth and more productive. For example, Jenkin (open-source tool) is used widely to automate builds and tests. CircleCI and Buddy, on the other hand, are commercial tools. Well, whatever tools you select for continuous integration, pick the one that can fit your business and project requirements.

3. Continuous testing
	Some teams carry out the continuous testing phase before the integration occurs, while others do it after the integration. Quality analysts continuously test the software for bugs and issues during this stage using Docker containers. In case of a bug or an error, the code is sent back to the integration phase for modification. Automation testing also reduces the time and effort to deliver quality results. Teams use tools like Selenium at this stage.

Tools Used: JUnit, Selenium, TestNG, and TestSigma are a few DevOps tools for continuous testing. Selenium is the most popular open-source automation testing tool that supports multiple platforms and browsers. TestSigma, on the other hand, is a unified AI-driven test automation platform that eliminates the technical complexity of test automation through artificial intelligence. 

4. Continuous deployment
	This phase is the crucial and most active one in the DevOps lifecycle, where final code is deployed on production servers. Development teams release the code to servers and schedule the updates for servers, keeping the configurations consistent throughout the production process. Containerization tools also help in the deployment process by providing consistency across development, testing, production, and staging environments. This practice made the continuous delivery of new features in production possible.

Tools Used: Ansible, Puppet, and Chef are the configuration management tools that make the deployment process smooth and consistent throughout the production process. Docker and  Vagrant are another DevOps tool used widely for handling the scalability of the continuous deployment process. Apart from this, Spinnaker is an open-source continuous delivery platform for releasing the software changes, while ArgoCD is another open-source tool for Kubernetes native CI/CD.

5. Continuous feedback
	Continuous feedback came into existence to analyze and improve the application code. During this phase, customer behavior is evaluated regularly on each release to improve future releases and deployments. Businesses can either opt for a structural or unstructured approach to gather feedback. In the structural approach, feedback is collected through surveys and questionnaires. In contrast, the feedback is received through social media platforms in an unstructured approach.

Tools Used: Pendo is a product analytics tool used to collect customer reviews and insights. Qentelli’s TED is another tool used primarily for tracking the entire DevOps process to gather actionable insights for bugs and flaws.

6. Continuous monitoring
	During this phase, the application’s functionality and features are monitored continuously to detect system errors such as low memory, non-reachable server, etc. This process helps the IT team quickly identify issues related to app performance and the root cause behind it. If IT teams find any critical issue, the application goes through the entire DevOps cycle again to find the solution. However, the security issues can be detected and resolved automatically during this phase.  

Tools Used: Nagios, Kibana, Splunk, PagerDuty, ELK Stack, New Relic, and Sensu are a few DevOps tools used to make the continuous monitoring process fast and straightforward.

7. Continuous operations
	The last phase in the DevOps lifecycle is crucial for reducing the planned downtime, such as scheduled maintenance. Generally, developers are required to take the server offline to make the updates, which increases the downtime and might even cost a significant loss to the company. Eventually, continuous operation automates the process of launching the app and its updates. It uses container management systems like Kubernetes and Docker to eliminate downtime. These container management tools help simplify the process of building, testing, and deploying the application on multiple environments. The key objective of this phase is to boost the application’s uptime to ensure uninterrupted services. Through continuous operations, developers save time that can be used to accelerate the application’s time-to-market. 

Tools Used: Kubernetes and Docker Swarm are the container orchestration tools used for the high availability of the application and to make the deployment faster.

[Additional Link: https://www.simform.com/blog/devops-tools/]


	Simple scenario, consider you are working as a DevOps Engineer in a company where you have been given task to deploy an application, The code for this application has been written and given to you by Developer. Now, the code is available in our local machine and ready to deploy; Here in this scenario we are facing issues like if we lose our machine our code is gone, so the best practice is to 1st create a repository and push the code on version control systems like (GIT, GitHub, GitLab, Bitbucket etc.,) this has different benefits like different branches for different version of your application, different people working on the same application, we can roll back if there comes an issue, end of the day we have a secure place to push our code securely from any part of the world. 

   	Understand the difference between Git & GitHub (Git is a software, provide command line support, installed locally on the system, maintained by linux) whereas (Github is a service, provides an interface to connect with git repositories, hosted on web, maintained by Microsoft)

   	Now, in order to access the application we need to deploy this code on Cloud, in order to deploy the code we have 2 options (1.Servers or 2. Containers) - under which situations we select these? Let's consider for now we don't have much traffic and we don't want to scale higher, during this kind of situations we will stick with servers; normally one create server by going inside the compute and give all the requirements like (ram, os, volume, keypair etc.,) but as a DevOps engineer we will not follow this method, instead we will use IAC (Infrastructure as Code) by using tools like Terraform, cloudformation, Pulumi etc., where we will provide the informations about infrastructure in the form of code and apply to get the servers on the cloud [why IAC? by writing code we can reuse this on different environments like staging, dev and prod, by this way it reduces the time and effort to bring our Infrastructure]
	Before deploying our application, let's consider now this application written in Python language in order run this application on server we need to install Python along with it's dependencies, others will run the commands to install all this requirements on multiple machines, but as a DevOps engineer we won't do this manually instead we will use configuration management tools (like Ansible, Chef, Puppet, Saltstack) to automate the process, through this way we can configure the servers and install the necessary softwares. [The idea is you need to define the configuration in the form of code so we can tell, install Python, install database, start the database, add the query, etc., everything in code run it inside the servers, this is called CAAC configuration as a Code]
	Finally our server is ready and configured to run our application, so we can clone the code and we can deploy the application, connected the IP address with the Domain name using DNS, so anyone on the Internet can access the applications without any issues.
    	Now, this is not a 1 time process, because we are going to keep on updating our application with new features, if manually we are going to do the process, we need to build, test and deploy each and every time, and this is not as easy as it looks, now in order to automate this we need to bring CI/CD [Continuous Integration/Continuous Deploymentmethod to frequently deliver apps to customers by introducing automation into the stages of app development], using CI/CD pipeline we can automate the process of Building, testing & deploying application on the server. 
	Whenever a push made to the version control system, the build should be created and  automatically deployed on the server, 
[this can be done using different tools like Jenkins, GitHub Actions, Circle CI, Travis CI etc.,] CI/CD is one of the most important aspects of DevOps.

	Now let's consider our application got popular and the traffic are very high so we need to convert our applications into an micro-services architecture where we need to deploy all our features/components into a separate containers using Docker, the most popular tool for container. In order to run our applications of Docker, we need to create a Dockerfile [a text file that contains all commands, port details, dependencies for our application, by building this file we can bring a Docker image (docker build -t (image name)) - we can store these image on Docker hub or other registries like (ECR, ACR, GCR, ACCR, etc.,) - anyone can pull this image if it is public, but private images can be pulled only from your organization who got access, and by running this container we can get our applications.

[What is the difference between Monolithic and Micro-services architecture?
	In Monolithic architecture our applications is deployed in single big unit, wherein all the software components of an app are assembled and tightly coupled, here the advantages are it is easy to develop & deploy our application, but the same time the disadvantages where it is difficult to to maintain & scale, also if one of the component fails the entire application brought down. 
	In Microservices, the architecture is connected with a small independent units that work together to form a large application, each services is responsible for different functions and these talk through APIs, so these are loosely coupled, due to this if one of the service is down it will not affect the other services; it is easy to scale, but the disadvantage here is to have more knowledge at the time of develop & deployment and that is comparitively difficult]
	
	In order to manage multiple containers, we need to use an container orchestration tool (like kubernetes, redhat openshift etc.,) - Kubernetes is the most popular tool where we can manage different containers of an application, we can define about the replicas, volumes, networks etc., this tool provides a way to manage and automate the deployment of an application that is running on Docker containers, now finally we got our application on Kubernetes clusters.

	Next, we have GitOps [this uses Git repositories as a single source of truth to deliver infrastructure] with kubernetes we can automate the deployment and management of containerized application, the popular tools are (Argo CD & FluxCD), the idea is to define the manifest file on Git repositories, whenever there is a change these is going to be reflected on Kubernetes cluster, [whenever there is a change done on Git repositories this will get applied on Kubernetes clusters without using any additional commands] 
	Once everything is ready we need to monitor them, where we are checking the health of an applications, confirming success for all the requests, [popular tools like prometheus, nagios, splunk etc.,] along with this we can also use alerting services or tools like SNS, slack, Pagerduty to receive notifications whenever there is a failure or during the application is down.

Free DevOps Lab Access: https://kodekloud.com/pages/free-labs








