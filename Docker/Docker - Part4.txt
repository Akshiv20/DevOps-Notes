Docker - Part 1

Docker Swarm:	
=============
     Docker Swarm is Docker‚Äôs native clustering and orchestration tool that allows you to manage a group of Docker engines as a single virtual Docker host. Essentially, it transforms multiple Docker nodes into a single, manageable cluster, providing built-in container orchestration capabilities.

	Docker Swarm is a tool that helps you run multiple containers on different computers (nodes) and manage them like a single system. Think of it like a team of servers (machines) working together to run your applications. Instead of running Docker on just one server, Docker Swarm lets you connect many servers and share the work.

For example, if you're running a website and get a lot of traffic, running it on one machine might slow it down. With Docker Swarm, you can run your website on 5 different servers, and Docker Swarm will distribute the workload automatically.

	Unlike Kubernetes, which has a more complex setup and steeper learning curve, Docker Swarm is natively integrated into the Docker Engine. This makes it extremely easy to get started with for teams already using Docker. With a few simple commands, developers can deploy replicated services, scale applications across nodes, and maintain high availability with minimal overhead.

Why Use Docker Swarm in Real Projects?
======================================
In real projects, we often need to make sure our applications:
 > Don‚Äôt stop if one server fails
 > Can handle more users by adding more servers
 > Are easy to update without turning them off

Docker Swarm helps with all of this. It makes sure containers are spread across servers, and if one container or machine crashes, another one takes over. This helps keep the application running smoothly.

Example:
--------
A food delivery app is used by thousands of people. It runs on Docker containers. With Docker Swarm, the app runs on 3 servers. If one server fails, the others keep it running, and users never notice a problem.

Benefits of Choosing Docker Swarm
=================================
There are several compelling reasons to use Docker Swarm:
 > Simplicity and Integration: Built into Docker CLI and Engine‚Äîno additional tools needed.
 > Faster Learning Curve: Easier for teams already familiar with Docker.
 > Lightweight: Uses fewer system resources than Kubernetes.
 > Secure by Default: Communication between nodes is encrypted using mutual TLS (Transport Layer Security)
 > Declarative Service Model: Define the desired state of services using YAML or CLI.
 > Scalability: Easily scale services with a single command.
 > Built-in Load Balancing: Automatically routes traffic between services.

These benefits make Swarm suitable for startups, small-to-medium-sized companies, or non-critical workloads where Kubernetes might be overkill.

Alternate Tools for Docker Swarm
=================================
While Docker Swarm is useful, there are several other container orchestration tools used in the industry:
 > Kubernetes (K8s): The most popular orchestration platform with robust features like custom resource definitions, persistent volumes, and extensive ecosystem support.
 > Nomad by HashiCorp: A simpler alternative to Kubernetes with strong multi-cloud capabilities.
 > Amazon ECS (Elastic Container Service): AWS-native orchestration service for deploying containers.
 > Apache Mesos: A more complex framework for managing clusters beyond just containers.

Docker Swarm holds its place for quick, Docker-native orchestration, especially in environments where Kubernetes complexity is not justified.

Steps:
======
Objective: Set up a 3-node Docker Swarm cluster and deploy a replicated web service.

Installation and Setup:
-----------------------

1. Create 3 EC2 machines (Ubuntu 22.04) - open all ports - 30Gib [Rename one machine as Manager Node]

Add this in the User data:
#!/bin/bash
sudo apt update && sudo apt install -y docker.io
sudo systemctl enable docker
sudo systemctl start docker

2. Open terminal - change as root user (sudo su -) - run the command (docker swarm init --advertise-addr <MANAGER public IP>), now we can see a token, copy that

[Sample token: docker swarm join --token SWMTKN-1-616zxfhlin1lbq59q1qtppw62lk6ln0rskinypqvzo6kpmslz1-5trdt2r359cs7zp5g0mr5hkwb 52.14.181.1:2377]

3. Connect with both the worker machines - change as root user (sudo su -) and paste the token on both the machines; we will get a confirmation message like [This node joined a swarm as a worker]

4. Come to the Manager node, give command (docker node ls) we can see the nodes has been added accordingly; and this will show the leader node also

Deploy a Service (Application):
-------------------------------
What is a ‚ÄúService‚Äù in Docker Swarm?
	In Docker Swarm, a service is simply your application running as containers across multiple machines (called nodes).

You can think of it like this:

	"A service = an app (or microservice) + how many copies of it should run + on which machines."

So when you create a service, you‚Äôre telling Swarm:
 . "Run this app using this Docker image"
 . "I want 3 copies (replicas)"
 . "Distribute them across the cluster automatically"

üß† Example:
If you have a web app and run it as a service with 3 replicas, Docker Swarm might:
 . Run 1 container on node-1
 . Run 1 container on node-2
 . Run 1 container on node-3
Swarm handles all of this automatically.

Where Does the Service Run?
 . You create the service on a manager node, using the Docker CLI.
 . The manager node decides where to run the containers.
 . The actual containers can run on manager or worker nodes ‚Äî yes, even on the manager, unless you configure it otherwise.
 . If you want only workers to run containers, you can use a constraint.

üìå Note:
By default, manager nodes can also run containers, so your service may end up there too unless you restrict it.

1. Now let us deploy a service, give the command (docker service create --name web-app --replicas 3 -p 8080:80 nginx)

What this does:
	--name my-web-app: Names your service (useful for tracking and updating later).
	--replicas 3: Tells Swarm to run 3 copies of the app.
	-p 8080:80: Maps port 80 in the container to port 8080 on your host (you can access it via http://<node-ip>:8080).
	nginx: This is the image being used. You could use nginx, node, myapp:latest, etc.

üß† In simple words:
‚ÄúRun 3 instances of this web app and expose it on port 8080.‚Äù

2. Check the service status

docker service ls

What this shows:
 > ID
 > Name of the service
 > Number of replicas running (e.g., 3/3 means all are running)
 > Image used
 > Ports exposed

üß† In simple words:
‚ÄúShow me all running services and whether they are healthy.‚Äù

docker service ps web-app

What this shows:
 > Which node each replica is running on
 > Task status (running, preparing, failed, etc.)
 > Container ID
 > Current state (like running for 2 minutes)

üß† In simple words:
‚ÄúWhere are the parts of my app running in the cluster?‚Äù

3. let us try to scale the service, by giving command (docker service scale web-app=5)

What this does:
 > Changes the number of replicas to 5
 > Docker Swarm will create 2 more containers if only 3 were running before

üß† In simple words:
‚ÄúIncrease the number of running app copies to 5.‚Äù

[*** You can scale down too: by giving the command (docker service scale my-web-app=2)

4. Let us perform the Rolling updates (docker service update --image nginx:alpine web-app) 

What this does:
 > Tells Swarm to update the running containers one-by-one (rolling update)
 > It pulls the new image (nginx:alpine)
 > Restarts each container one at a time to avoid downtime

üß† In simple words:
‚ÄúUpdate the app to a new version smoothly, without shutting down everything at once.‚Äù

Real-Life Example
-----------------
Let‚Äôs say you have a Node.js shopping app and you want to run it across multiple machines with high availability. Here's how Swarm helps:

1. You create a service with 4 replicas.
2. Docker Swarm spreads those 4 containers across 3 nodes.
3. If one node fails, Swarm automatically moves the container to another healthy node.
4. You later want to update your app to v2 ‚Äî Swarm performs rolling updates without any downtime.
5. You get load balancing automatically ‚Äî Swarm will direct user traffic to all 4 containers evenly.


Docker Health Checks:
=====================
	Docker Health Checks allow you to specify a command within the Dockerfile that determines whether a container is healthy or not. This is useful when just knowing that the container is running (i.e., not exited) is insufficient. For example, a web server container might be "running" but if the server inside it has crashed, it is not actually "healthy."

Health checks help in automation of recovery, rolling updates, and load balancing decisions. Orchestration systems like Docker Swarm or Kubernetes can restart or replace unhealthy containers automatically.

In Simple words,
	A Docker Health Check tells Docker if your app inside the container is working or not.

	Just because a container is running doesn‚Äôt mean your app is working. Maybe the app crashed or got stuck. A health check runs a small test (like calling a URL) to check if everything is okay.

Example:
If your app is a website, the health check could be:
‚ÄúOpen the homepage. If I get a 200 OK, it‚Äôs healthy. If not, something‚Äôs wrong.‚Äù

Real-Time Usage of Docker Health Checks
========================================
Imagine a Node.js application container that sometimes hangs due to memory leaks. With a health check in place, Docker periodically runs the defined check, and if the application becomes unresponsive (e.g., HTTP 500 or timeout), Docker marks it as unhealthy. In a production cluster, this can automatically trigger container restarts, avoiding manual intervention and increasing uptime.

In enterprise applications, health checks are often used for:
 > Microservices: Checking whether each microservice responds to internal APIs.
 > Database containers: Verifying database connectivity or port responsiveness.
 > API gateways: Ensuring that routing services are live and listening.

Advantages of Using Docker Health Checks
========================================
 . Improved Automation: Enables systems to auto-heal unhealthy containers.
 . Better Monitoring: Explicit visibility into container state.
 . Zero-Downtime Deployments: Helps orchestration tools wait for healthy containers before routing traffic.
 . Fault Isolation: Prevents broken containers from impacting overall performance.

Steps:
======
1. Create a simple Dockerfile (vi Dockerfile), paste the content

FROM nginx:alpine

# Optional: copy custom Nginx config
# COPY default.conf /etc/nginx/conf.d/default.conf

HEALTHCHECK --interval=10s --timeout=3s --start-period=5s --retries=3 \
  CMD wget -q --spider http://localhost || exit 1

| Option              | Meaning                                                                 |
| ------------------- | ----------------------------------------------------------------------- |
| `--interval=10s`    | Docker checks health every 10 seconds                                   |
| `--timeout=3s`      | If the command takes longer than 3s, it's considered a failure          |
| `--start-period=5s` | Wait 5 seconds after container starts before health checks begin        |
| `--retries=3`       | If it fails 3 times in a row, mark container as `unhealthy`             |
| `CMD`               | This is the health check itself ‚Äì here it checks if NGINX is responding |

Command Explanation:
wget -q --spider http://localhost || exit 1

 . wget -q --spider http://localhost: Checks if something is responding on port 80 inside the container.
 . || exit 1: If it fails, return non-zero exit status (meaning unhealthy)

2. Build the Image, (docker build -t nginx-healthcheck .)

3. Run the Container (docker run -d --name web nginx-healthcheck)

4. Check container health (docker inspect --format='{{json .State.Health}}' web) [You‚Äôll see the health status: healthy, unhealthy, or starting.]

5. go inside the container, and remove the Nginx config file ro see the health check failure:

docker exec -it web sh
rm /etc/nginx/conf.d/default.conf

exit from the container

and kill nginx process itself (docker exec -it <container-id> pkill nginx); give few mints and run the command 4; where we can see the health check failed.

Docker Ecosystem:
=================
	The Docker Ecosystem refers to the collection of tools, services, and best practices built around Docker for building, shipping, and running containers efficiently in various environments. It is not limited to just the Docker Engine but encompasses a broader range of components that work together to provide end-to-end container lifecycle management.

This ecosystem ensures seamless collaboration between developers, operations teams, CI/CD pipelines, monitoring tools, and infrastructure provisioning frameworks.

In Simple words,
 The Docker Ecosystem means all the tools and features that help you build, run, and manage containers. Docker is not just about running a container. You also need to:

 . Write Dockerfiles
 . Build images
 . Share images
 . Monitor containers
 . Connect multiple containers
 . Secure your containers
The Docker ecosystem gives you everything in one place.

Usage of Docker Ecosystem in Real-Time Projects
===============================================
In enterprise applications, teams use the Docker ecosystem for:
 > CI/CD Pipelines: Tools like Jenkins, GitLab CI, or GitHub Actions run Docker containers for isolated builds and deployments.
 > Container Registries: Docker Hub, JFrog Artifactory, or Amazon ECR for storing and distributing images.
 > Monitoring & Logging: Prometheus, Grafana, ELK stack monitor running containers and collect logs.
 > Security Scanning: Tools like Trivy, Clair, or Snyk scan container images for vulnerabilities.
 > Orchestration & Scaling: Docker Swarm or Kubernetes scale and manage container lifecycles.

Components of the Docker Ecosystem
===================================
Here‚Äôs a breakdown of the key elements in the Docker ecosystem:
 . Docker Engine: Core component for running containers.
 . Docker CLI: Command-line interface for Docker operations.
 . Docker Compose: Tool for defining and running multi-container applications.
 . Dockerfile: Blueprint for creating Docker images.
 . Docker Swarm/Kubernetes: For orchestration and cluster management.
 . Docker Hub / Private Registry: For storing Docker images.
 . Docker Desktop: GUI for managing containers (mostly for developers).
 . Docker Plugin System: For extending functionality with volume/network plugins.
 . Docker API: Allows automation tools to interact with the Docker daemon.















































